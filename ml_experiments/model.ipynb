{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0bff1c",
   "metadata": {},
   "source": [
    "# Private XGBoost on Fingerprint\n",
    "\n",
    "### Set up\n",
    "\n",
    "Install dependencies from https://github.com/awslabs/privacy-preserving-xgboost-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "628d5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppxgboost import PPPrediction as prediction\n",
    "import ppxgboost.PPModel as PPModel\n",
    "from ppxgboost import PaillierAPI as paillier\n",
    "import ppxgboost.OPEMetadata as OPEMetadata\n",
    "import ppxgboost.PPKey as PPKey\n",
    "import ppxgboost.PPQuery as PPQuery\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from secrets import token_bytes\n",
    "import pyope.ope as pyope\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import imageio\n",
    "from skimage.morphology import skeletonize, thin\n",
    "from skimage import io, img_as_bool, img_as_ubyte\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.feature import canny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b34734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    image = cv2.GaussianBlur(image, (3, 3), 0)\n",
    "\n",
    "    # Binarize the image using Otsu's threshold\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "   \n",
    "    skeleton = skeletonize(binary_image//255)\n",
    "    skeleton = img_as_ubyte(skeleton)  \n",
    "\n",
    "    return skeleton\n",
    "\n",
    "def extract_minutiae(skeleton):\n",
    "   \n",
    "    kernel = np.uint8([[0, 0, 0], [1, 1, 0], [0, 1, 0]])\n",
    "    minutiae = cv2.morphologyEx(skeleton, cv2.MORPH_HITMISS, kernel)\n",
    "\n",
    "    # Convert minutiae points to coordinates\n",
    "    minutiae_locations = np.column_stack(np.where(minutiae > 0))\n",
    "\n",
    "    return minutiae_locations\n",
    "\n",
    "def create_feature_vector(minutiae_points, image_shape, grid_size=(8, 8)):\n",
    "    feature_vector = np.zeros(grid_size[0] * grid_size[1])\n",
    "\n",
    "    # Calculate cell size\n",
    "    cell_height = image_shape[0] // grid_size[0]\n",
    "    cell_width = image_shape[1] // grid_size[1]\n",
    "\n",
    "    for minutia in minutiae_points:\n",
    "        # Determine the grid cell for this minutia\n",
    "        row = minutia[0] // cell_height\n",
    "        col = minutia[1] // cell_width\n",
    "\n",
    "        # Calculate the index in the feature vector\n",
    "        index = row * grid_size[1] + col\n",
    "        feature_vector[index] += 1  \n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "090c724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "\n",
    "  # Create empty lists to store the images and labels\n",
    "  images = []\n",
    "  labels = []\n",
    "  features = []\n",
    "\n",
    "  # Iterate over all of the files in the folder\n",
    "  for filename in os.listdir(folder):\n",
    "\n",
    "    # Read the image into memory\n",
    "    img = cv2.imread(os.path.join(folder,filename), cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (160,160))\n",
    "    # Check to make sure that the image is not None\n",
    "    if img is not None:\n",
    "          skeleton_image = preprocess_image(img)\n",
    "          minutiae_feature = extract_minutiae(skeleton_image)\n",
    "          # Add the image and label to the corresponding lists\n",
    "          images.append(img)\n",
    "          labels.append(int(filename.split('_')[0].split('.')[0]))\n",
    "          features.append(create_feature_vector(minutiae_feature,img.shape))\n",
    "\n",
    "  # Return the images and labels\n",
    "  return images, labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c52a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change location of dateset if necessary\n",
    "_, y_train, x_train = load_images_from_folder('../data/dataset_FVC2000_DB4_B/dataset/train_data')\n",
    "_, y_test, x_test = load_images_from_folder('../data/dataset_FVC2000_DB4_B/dataset/real_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be1889d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid\n",
    "col = 8\n",
    "row = 8\n",
    "grid = []\n",
    "for i in range(row):\n",
    "    for j in range(col):\n",
    "        grid.append(\"(\"+str(i)+\",\"+str(j)+\")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2311720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 800\n",
      "Shape of the training: (800, 64)\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of training images to a NumPy array\n",
    "x_train = pd.DataFrame(x_train)\n",
    "\n",
    "# Convert the list of test images to a NumPy array\n",
    "x_test = pd.DataFrame(x_test)\n",
    "\n",
    "# Print the number of training images and the shape of the first training image\n",
    "print(\"Number of training images:\", len(x_train))\n",
    "print(\"Shape of the training:\", x_train.shape)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92eef790",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns = grid\n",
    "x_test.columns = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cdfb52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=20, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=20, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softmax&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=20, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_estimaters = 20\n",
    "model = xgb.XGBClassifier(n_estimators=total_estimaters, objective='multi:softmax')\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c851a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba3c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = model.n_classes_\n",
    "\n",
    "# Create custom data ranges\n",
    "in_range = pyope.ValueRange(pyope.DEFAULT_IN_RANGE_START, 2 ** 43 - 1)\n",
    "out_range = pyope.ValueRange(pyope.DEFAULT_OUT_RANGE_START, 2 ** 63 - 1)\n",
    "\n",
    "# parse the tree\n",
    "ppModel = PPModel.from_xgboost_model(model.get_booster())\n",
    "features = ppModel.get_features()\n",
    "#  (add fake test data range here as this testing only test the model correctness)\n",
    "metadata = OPEMetadata.OPEMetadata(ppModel, 0, 100, in_range.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b73b2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up encryption materials.\n",
    "ppModelKey, ppQueryKey = PPKey.generatePPXGBoostKeys(in_range, out_range)\n",
    "\n",
    "# 1. process the tree into ope_enc_tree\n",
    "enc_model = ppModel.encrypt(ppModelKey, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c212ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encrypts the input vector for prediction (using prf_key_hash and ope-encrypter) based on the feature set.\n",
    "import ppxgboost.PPQuery as PPQuery\n",
    "queryEncryptor = PPQuery.QueryEncryptor(ppQueryKey, features, metadata)\n",
    "queries = PPQuery.pandas_to_queries(x_test)\n",
    "enc_queries = PPQuery.encrypt_queries(queryEncryptor, queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc1ee18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. OPE evaluation based on OPE encrypted values in the tree nodes.\n",
    "enc_predictions = prediction.predict_multiclass(enc_model, num_classes, enc_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e294d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = prediction.client_decrypt_prediction_multiclass(ppQueryKey.get_private_key(), enc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a8e46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "real_y = model.predict(x_test)\n",
    "assert np.array_equal(result, real_y)\n",
    "print(\"success!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a1617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
